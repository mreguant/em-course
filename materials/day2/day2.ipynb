{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Supply I\n",
    "\n",
    "We talked today about how electricity markets work.\n",
    "\n",
    "We will learn today how to build a simple model of an electricity market using **JuMP**.\n",
    "\n",
    "The data and code are based on the paper \"The Efficiency and Sectoral Distributional Implications of Large-Scale Renewable Policies,\" by Mar Reguant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load relevant libraries.\n",
    "\n",
    "Compared to day 1, we will be adding the libraries `JuMP` and the non-linear solver `Ipopt`. We will also be using the clustering library `Clustering` and the package `Random` to control the randomness in the machine learning algorithm.\n",
    "\n",
    "**Note:** I often prefer to use commercial solvers (Gurobi or CPLEX), which are available under an academic license. I use solvers that are readily available here without a license for simplicity and to ensure that everyone can access the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add([ \"StatsPlots\",\"StatsBase\",\"Clustering\",\"Random\",\"JuMP\",\"Ipopt\",\"Printf\"])\n",
    "\n",
    "using DataFrames\n",
    "using CSV\n",
    "using Plots\n",
    "using StatsPlots\n",
    "using Statistics, StatsBase\n",
    "using Clustering\n",
    "using Random\n",
    "using JuMP\n",
    "using Ipopt\n",
    "using Printf\n",
    "using FixedEffectModels\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data using the CSV syntax (`CSV.read`) into a data frame called `df`.  Here we need to do some cleaning of the variables, rescaling and dropping missing entries.\n",
    "\n",
    "Having a clean dataset will be very helpful for the clustering algorithm, which requires complete rows of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the data and clean it up a bit\n",
    "df = CSV.read(\"data_jaere.csv\", DataFrame)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sort(df,[\"year\",\"month\",\"day\",\"hour\"])\n",
    "df = dropmissing(df)\n",
    "df.nuclear = df.nuclear/1000.0\n",
    "df.hydro = df.hydro/1000.0\n",
    "df.imports = df.imports/1000.0\n",
    "df.q_commercial = df.q_commercial/1000.0\n",
    "df.q_industrial = df.q_industrial/1000.0\n",
    "df.q_residential = df.q_residential/1000.0\n",
    "df.hydronuc = df.nuclear + df.hydro \n",
    "df = select(df,Not([\"nuclear\",\"hydro\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "When modeling electricity markets, oftentimes the size of the problem can make the solver slow.\n",
    "\n",
    "Here we will be using a clustering algorithm to come up with a (much) smaller synthetic dataset that we will use for the purposes of our main analysis.\n",
    "\n",
    "**Note:** We ignore the time variables when we cluster. In our case, we'll transform a dataset of 43408 hours to 100 representatives hours. That is enough if you assume no correlation between hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of clusters\n",
    "n = 100\n",
    "# Clustering algorithms work in rows, so we need to transpose our data\n",
    "X = transpose(Array(select(df,Between(:price,:hydronuc))));\n",
    "\n",
    "# We scale variables to improve kmeans performance. For that, we take the mean and std of each row (dim=2) and you repeat it by the number of columns (rows in df)\n",
    "Xs = (X.- repeat(mean(X,dims=2),1,nrow(df)))./repeat(std(X,dims=2),1,nrow(df)); \n",
    "\n",
    "#we set seed because kmeans picks random samples to generate clusters\n",
    "Random.seed!(2020)\n",
    "R = kmeans(Xs, n);\n",
    "\n",
    "# Get the cluster centers rescaling again. These centers will be the new observations\n",
    "M = R.centers .* repeat(std(X,dims=2),1,n) .+ repeat(mean(X,dims=2),1,n);  \n",
    "\n",
    "# Assignments of each cluster\n",
    "A = assignments(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclust = DataFrame(transpose(M),\n",
    "\t[\"price\", \"imports\", \"q_commercial\", \"q_industrial\", \"q_residential\", \n",
    "\t\t\t\"wind_cap\", \"solar_cap\", \"hydronuc\"]);\n",
    "    # the weights is defined by the number of old observations assigned to each cluster          \n",
    "\tdfclust.weights = counts(R);\n",
    "\tfirst(dfclust, 5)\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the distribution of outcomes between the original dataset and the new dataset.\n",
    "\n",
    "Here is an example with prices. The two distributions are very similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(df.price, fillalpha=.2, nbins=20, label=\"Data\")\n",
    "\thistogram!(dfclust.price,weights=dfclust.weights, \n",
    "\tfillalpha=.2, nbins=20, \n",
    "\t\tlabel=\"Clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also relatively well matched for the case for solar, although it is harder there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(df.solar_cap, fillalpha=.2, nbins=20, label=\"Original\")\n",
    "\thistogram!(dfclust.solar_cap, weights=dfclust.weights, fillalpha=.2, nbins=20, label=\"Clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the output\n",
    "\n",
    "It is useful to save the clustered data so that we can use it directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"data_jaere_clustered.csv\", dfclust)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Now that we have clustered our data, we will build our model with the data that we have. \n",
    "\n",
    "The model that we will build today is a simplification from the original paper.\n",
    "\n",
    "In the original paper, the model needed to solve for:\n",
    "1. Endogenous retail prices (in a demand model, iterated to find equilibrium)\n",
    "2. Endogenous investment (in same supply model, with more equations)\n",
    "\n",
    "Here we will be simply building a simple model of market clearing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the model, we define some model parameters related to:\n",
    "\n",
    "* Number and costs of different technologies (loaded from a small dataset)\n",
    "\n",
    "* Elasticity of demand and imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = CSV.read(\"data_technology_simple.csv\", DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume zero marginal costs for renewable energy. `capUB` defines the maximum capacity of each power plant. For the existing ones, it defines the maximum production. For renewables, they will always produce at maximum capacity (precisely because of zero marginal costs) but production will depend on the capacity factors defined before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calibrate demand, one can use different strategies. Here we compute the slope for the demand curve that is consistent with the assumed elasticity of demand. \n",
    "\n",
    "Notice that this is a local elasticity approximation, but it has the advantage of being a linear demand curve, which is very attractive for the purposes of linear programming.\n",
    "\n",
    "The demand is: $ q = a - b \\ p $\n",
    "\n",
    "So the elasticity becomes: $elas =  b  \\frac{p}{q} $, which we set equal to an assumed parameter.\n",
    "\n",
    "Once we have $b$, we can back out $a$. \n",
    "\n",
    "An analogous procedure is done for imports, but in this case, $ qm = am + bm \\ p $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclust.weights = dfclust.weights / sum(dfclust.weights);\n",
    "\t\n",
    "\t# Here only one demand type to make it easier\n",
    "\tdfclust.demand = dfclust.q_residential + dfclust.q_commercial + dfclust.q_industrial;\n",
    "\t\n",
    "    # Calibrate demand based on elasticities (using 0.1 here as only one final demand)\n",
    "\telas = [.1, .2, .5, .3];\n",
    "\tdfclust.b = elas[1] * dfclust.demand ./ dfclust.price;  # slope\n",
    "\tdfclust.a = dfclust.demand + dfclust.b .* dfclust.price;  # intercept\n",
    "\n",
    "\t# Calibrate imports (using elas 0.3)\n",
    "    dfclust.bm = elas[4] * dfclust.imports ./ dfclust.price;  # slope\n",
    "    dfclust.am = dfclust.imports - dfclust.bm .* dfclust.price;  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(dfclust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear solver\n",
    "\n",
    "We are now ready to clear the market. We will **maximize welfare** using a non-linear solver.\n",
    "\n",
    "$ \\max \\ CS - Costs $\n",
    "\n",
    "$ \\text{s.t.} \\ \\text{operational constraints, market clearing}. $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function clear_market_max(data::DataFrame, tech::DataFrame; \n",
    "    wind_gw = 5.0, solar_gw = 2.0)\n",
    "\n",
    "# We declare a model\n",
    "model = Model(\n",
    "    optimizer_with_attributes(\n",
    "        Ipopt.Optimizer)\n",
    "    );\n",
    "\n",
    "# Set useful indexes\n",
    "I = nrow(tech);  # number of techs\n",
    "T = nrow(data);  # number of periods\n",
    "S = 1;  # we will only be using one sector to keep things simple\n",
    "\n",
    "# Variables to solve for\n",
    "@variable(model, price[1:T]);\n",
    "@variable(model, demand[1:T]);\n",
    "@variable(model, imports[1:T]);\n",
    "@variable(model, quantity[1:T, 1:I] >= 0);\n",
    "\n",
    "# Maximize welfare including imports costs\n",
    "@NLobjective(model, Max, sum(data.weights[t] * (\n",
    "            (data.a[t] - demand[t]) * demand[t] / data.b[t] \n",
    "        + demand[t]^2/(2*data.b[t])\n",
    "    - sum(tech.c[i] * quantity[t,i] \n",
    "                + tech.c2[i] * quantity[t,i]^2/2 for i=1:I)\n",
    "    - (imports[t] - data.am[t])^2/(2 * data.bm[t])) for t=1:T));\n",
    "\n",
    "# Market clearing\n",
    "@constraint(model, [t=1:T], \n",
    "    demand[t] == data.a[t] - data.b[t] * price[t]);\n",
    "@constraint(model, [t=1:T], \n",
    "    imports[t] == data.am[t] + data.bm[t] * price[t]);\n",
    "@constraint(model, [t=1:T], \n",
    "    demand[t] == sum(quantity[t,i] for i=1:I) + imports[t]);\n",
    "\n",
    "# Constraints on output\n",
    "@constraint(model, [t=1:T], \n",
    "    quantity[t,1] <= data.hydronuc[t]);\t\n",
    "@constraint(model, [t=1:T,i=2:3], \n",
    "    quantity[t,i] <= tech[i,\"capUB\"]);\n",
    "@constraint(model, [t=1:T], \n",
    "    quantity[t,5] <= wind_gw * data.wind_cap[t]);\n",
    "@constraint(model, [t=1:T], \n",
    "    quantity[t,6] <= solar_gw * data.solar_cap[t]);\n",
    "\n",
    "# Solve model\n",
    "optimize!(model);\n",
    "\n",
    "status = @sprintf(\"%s\", JuMP.termination_status(model));\n",
    "\n",
    "if (status==\"LOCALLY_SOLVED\")\n",
    "    p = JuMP.value.(price);\n",
    "    avg_price = sum(p[t] * data.weights[t] for t=1:T);\n",
    "    q = JuMP.value.(quantity);\n",
    "    imp = JuMP.value.(imports);\n",
    "    d = JuMP.value.(demand);\n",
    "    cost = sum(data.weights[t] * (sum(tech.c[i] * q[t,i] \n",
    "            + tech.c2[i] * q[t,i]^2 / 2 for i=1:I) \n",
    "            + (imp[t] - data.am[t])^2/(2 * data.bm[t])) for t=1:T);\n",
    "    results = Dict(\"status\" => @sprintf(\"%s\",JuMP.termination_status(model)),\n",
    "        \"avg_price\" => avg_price,\n",
    "        \"price\" => p,\n",
    "        \"quantity\" => q,\n",
    "        \"imports\" => imp,\n",
    "        \"demand\" => d,\n",
    "        \"cost\" => cost);\n",
    "    return results\n",
    "else\n",
    "    results = Dict(\"status\" => @sprintf(\"%s\",JuMP.termination_status(model)));\n",
    "    return results\n",
    "end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = clear_market_max(dfclust, tech)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"avg_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can study the effects of an increase in renewable capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = clear_market_max(dfclust, tech, wind_gw = 7.0, solar_gw = 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"quantity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the relation between renewable production and prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = results[\"quantity\"][:,5]\n",
    "price = results[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(wind,price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-up exercise\n",
    "\n",
    "1. (*) The function is prepared to take several amounts of solar and wind. What are the impacts on prices as you increase solar and wind? Save prices for different values of wind or solar investment and plot them. Does your answer depend a lot on the number of clusters?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
